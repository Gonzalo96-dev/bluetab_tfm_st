# -*- coding: utf-8 -*-
"""Test 10000_de Vit_def

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iJaSWg1LEs1ep5CO8-msB30MtZlAd9rO
"""

gpu_info = !nvidia-smi
gpu_info = '\n'.join(gpu_info)
if gpu_info.find('failed') >= 0:
  print('Not connected to a GPU')
else:
  print(gpu_info)

from psutil import virtual_memory
ram_gb = virtual_memory().total / 1e9
print('Your runtime has {:.1f} gigabytes of available RAM\n'.format(ram_gb))

if ram_gb < 20:
  print('Not using a high-RAM runtime')
else:
  print('You are using a high-RAM runtime!')

from google.colab import drive
drive.mount('/content/drive')

import json
import numpy as np
import matplotlib.pyplot as plt
import os
import tensorflow as tf 
import pandas as pd

"""# EDA JSONS"""

json_file =  pd.read_json('/content/drive/Shareddrives/Proyecto_Final/Datasets/Photos/yelp_photos/photos.json', lines=True)
json_file = json_file[["photo_id", "label"]]

total_count = json_file[["label"]].count()
print(total_count)
print("food: " + str(108152/total_count*100))
print("inside: " + str(56031/total_count*100))
print("drink: " + str(18569/total_count*100))
print("outside: " + str(15670/total_count*100))
print("menu: " + str(1678/total_count*100))
json_file[["label"]].value_counts()

"""# Descomprimimos el .tar de las fotos en la carpeta content"""

!tar -xvf "/content/drive/Shareddrives/Proyecto_Final/Datasets/Photos_comprimido/yelp_photos.tar" -C "/content"

dir = "/content/photos"
len(os.listdir(dir))

"""Separamos las imágenes según las diferentes etiquetas en carpetas"""

import cv2
import  os

from google.colab.patches import cv2_imshow
image = cv2.imread('/content/photos/QMGtEDZvoIbaxBGBOsvMdg.jpg')
cv2_imshow(image)

import os
import shutil
import cv2
from google.colab.patches import cv2_imshow
import os.path


if not os.path.exists('/content/train/inside'):
  os.mkdir('/content/train/inside')
if not os.path.exists('/content/train/outside'):
  os.mkdir('/content/train/outside')
if not os.path.exists('/content/train/food'):
  os.mkdir('/content/train/food')
if not os.path.exists('/content/train/menu'):
  os.mkdir('/content/train/menu')
if not os.path.exists('/content/train/drink'):
  os.mkdir('/content/train/drink')

import shutil

n = 10000
n_food = n*0.54
n_inside = n*0.28
n_outside = n*0.078
n_drink = n*0.093
n_menu = n*0.0084

n_food_aux = 0
n_inside_aux = 0
n_outside_aux = 0
n_drink_aux = 0
n_menu_aux = 0

for index, row in json_file.iterrows():
    label = row['label']
    photo_id = row['photo_id']
    if label == "menu" and n_menu_aux<n_menu:
        shutil.copy2(os.path.join(os.sep, "content", "photos", f"{photo_id}.jpg"), os.path.join(os.sep, "content", "train", "menu", f"{photo_id}.jpg"))
        n_menu_aux = n_menu_aux + 1
    if label == "food" and n_food_aux<n_food:
        shutil.copy2(os.path.join(os.sep, "content", "photos", f"{photo_id}.jpg"), os.path.join(os.sep, "content", "train", "food", f"{photo_id}.jpg"))
        n_food_aux = n_food_aux + 1
    if label == "inside" and n_inside_aux < n_inside:
        shutil.copy2(os.path.join(os.sep, "content", "photos", f"{photo_id}.jpg"), os.path.join(os.sep, "content", "train", "inside", f"{photo_id}.jpg"))
        n_inside_aux = n_inside_aux + 1
    if label == "outside" and n_outside_aux < n_outside:
        shutil.copy2(os.path.join(os.sep, "content", "photos", f"{photo_id}.jpg"), os.path.join(os.sep, "content", "train", "outside", f"{photo_id}.jpg"))
        n_outside_aux = n_outside_aux + 1
    if label == "drink" and n_drink_aux < n_drink:
        shutil.copy2(os.path.join(os.sep, "content", "photos", f"{photo_id}.jpg"), os.path.join(os.sep, "content", "train", "drink", f"{photo_id}.jpg"))
        n_drink_aux = n_drink_aux + 1

import os
import shutil
import cv2
from google.colab.patches import cv2_imshow
import os.path

content_dir_1 = "/content/train/inside"
for filename in os.listdir(content_dir_1):
    im_path = os.path.join(content_dir_1, filename)
    try:
        im = cv2.imread(im_path)
        if im is None:
            print("La imagen no se ha leido correctamente, se borrará:", im_path)
            os.remove(im_path)
    except Exception as e:
        print("Error al leer la imagen, se borrará:", im_path)
        os.remove(im_path)

content_dir_2 = "/content/train/outside"
for filename in os.listdir(content_dir_2):
    im_path = os.path.join(content_dir_2, filename)
    try:
        im = cv2.imread(im_path)
        if im is None:
            print("La imagen no se ha leido correctamente, se borrará:", im_path)
            os.remove(im_path)
    except Exception as e:
        print("Error al leer la imagen, se borrará:", im_path)
        os.remove(im_path)

content_dir_3 = "/content/train/food"
for filename in os.listdir(content_dir_3):
    im_path = os.path.join(content_dir_3, filename)
    try:
        im = cv2.imread(im_path)
        if im is None:
            print("La imagen no se ha leido correctamente, se borrará:", im_path)
            os.remove(im_path)
    except Exception as e:
        print("Error al leer la imagen, se borrará:", im_path)
        os.remove(im_path)

content_dir_4 = "/content/train/drink"
for filename in os.listdir(content_dir_4):
    im_path = os.path.join(content_dir_4, filename)
    try:
        im = cv2.imread(im_path)
        if im is None:
            print("La imagen no se ha leido correctamente, se borrará:", im_path)
            os.remove(im_path)
    except Exception as e:
        print("Error al leer la imagen, se borrará:", im_path)
        os.remove(im_path)

content_dir_5 = "/content/train/menu"
for filename in os.listdir(content_dir_5):
    im_path = os.path.join(content_dir_5, filename)
    try:
        im = cv2.imread(im_path)
        if im is None:
            print("La imagen no se ha leido correctamente, se borrará:", im_path)
            os.remove(im_path)
    except Exception as e:
        print("Error al leer la imagen, se borrará:", im_path)
        os.remove(im_path)

"""LIMPIEZA IMAGENES DEFECTUOSAS"""

print(len(os.listdir('/content/train/drink')))
print(len(os.listdir('/content/train/inside')))
print(len(os.listdir('/content/train/outside')))
print(len(os.listdir('/content/train/food')))
print(len(os.listdir('/content/train/menu')))

total_fotos= len(os.listdir('/content/train/drink'))+len(os.listdir('/content/train/inside'))+len(os.listdir('/content/train/outside'))+len(os.listdir('/content/train/food'))+len(os.listdir('/content/train/menu'))
total_fotos

"""# Transformer"""

pip install -q transformers

# install datasets
!pip install datasets

import logging
import os
import sys
from dataclasses import dataclass, field
from typing import Optional

import numpy as np
import torch
from datasets import load_dataset
from PIL import Image
from torchvision.transforms import (
    CenterCrop,
    Compose,
    Normalize,
    RandomHorizontalFlip,
    RandomResizedCrop,
    Resize,
    ToTensor,
)

import transformers
from transformers import (
    MODEL_FOR_IMAGE_CLASSIFICATION_MAPPING,
    AutoConfig,
    AutoImageProcessor,
    AutoModelForImageClassification,
    HfArgumentParser,
    Trainer,
    TrainingArguments,
    set_seed,
)
from transformers.trainer_utils import get_last_checkpoint
from transformers.utils import check_min_version, send_example_telemetry
from transformers.utils.versions import require_version

pip install evaluate



# Commented out IPython magic to ensure Python compatibility.
# %run run_image_classification.py \
    --train_dir '/content/train' \
    --output_dir '/content/output' \
    --remove_unused_columns False \
    --do_train \
    --do_eval \
    --num_train_epochs 10 \
    --per_device_train_batch_size 32

import transformers 
print(transformers .__version__)